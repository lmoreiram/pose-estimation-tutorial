{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import MediaPipe Drawing module\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "# Import MediaPipe Pose module\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to draw keypoints and connections\n",
    "def draw_keypoints_and_connections(image, landmarks, mode):\n",
    "    # Get image dimensions\n",
    "    height, width, _ = image.shape\n",
    "    # Initialize list to the landmarks pixel coordinates\n",
    "    landmark_points = []\n",
    "    for landmark in landmarks:\n",
    "        landmark_point = (int(landmark.x * width), int(landmark.y * height))\n",
    "        landmark_points.append(landmark_point)\n",
    "\n",
    "    # Define connections for 'all' mode, excluding face and hand landmarks\n",
    "    connections_all = []\n",
    "    for conn in mp_pose.POSE_CONNECTIONS:\n",
    "        exclude = False\n",
    "        for lm in conn:\n",
    "            if lm in range(0, 11) or lm in range(17, 23):\n",
    "                exclude = True\n",
    "                break\n",
    "        if not exclude:\n",
    "            connections_all.append(conn)\n",
    "\n",
    "  \n",
    "    # Define connections for 'right' mode\n",
    "    connections_right = [\n",
    "        (mp_pose.PoseLandmark.RIGHT_SHOULDER, mp_pose.PoseLandmark.RIGHT_HIP),\n",
    "        (mp_pose.PoseLandmark.RIGHT_HIP, mp_pose.PoseLandmark.RIGHT_KNEE),\n",
    "        (mp_pose.PoseLandmark.RIGHT_KNEE, mp_pose.PoseLandmark.RIGHT_HEEL),\n",
    "        (mp_pose.PoseLandmark.RIGHT_HEEL, mp_pose.PoseLandmark.RIGHT_FOOT_INDEX)\n",
    "    ]\n",
    "    # Define connections for 'left' mode\n",
    "    connections_left = [\n",
    "        (mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.LEFT_HIP),\n",
    "        (mp_pose.PoseLandmark.LEFT_HIP, mp_pose.PoseLandmark.LEFT_KNEE),\n",
    "        (mp_pose.PoseLandmark.LEFT_KNEE, mp_pose.PoseLandmark.LEFT_HEEL),\n",
    "        (mp_pose.PoseLandmark.LEFT_HEEL, mp_pose.PoseLandmark.LEFT_FOOT_INDEX)\n",
    "    ]\n",
    "\n",
    "    # Determine which keypoints and connections to draw\n",
    "    keypoints_to_draw = set()\n",
    "    connections_to_draw = []\n",
    "\n",
    "    # Add keypoints and connections to draw based on the mode\n",
    "    if mode == 'all':\n",
    "        for idx in range(11, 17):\n",
    "            keypoints_to_draw.add(idx)\n",
    "        for idx in range(23, 33):\n",
    "            keypoints_to_draw.add(idx)\n",
    "        connections_to_draw = connections_all\n",
    "\n",
    "    elif mode == 'right':\n",
    "        for connection in connections_right:\n",
    "            keypoints_to_draw.add(connection[0])\n",
    "            keypoints_to_draw.add(connection[1])\n",
    "        connections_to_draw = connections_right\n",
    "\n",
    "    elif mode == 'left':\n",
    "        for connection in connections_left:\n",
    "            keypoints_to_draw.add(connection[0])\n",
    "            keypoints_to_draw.add(connection[1])\n",
    "        connections_to_draw = connections_left\n",
    "\n",
    "    # Draw the connections\n",
    "    for connection in connections_to_draw:\n",
    "        start_point = landmark_points[connection[0]]\n",
    "        end_point = landmark_points[connection[1]]\n",
    "        cv2.line(image, start_point, end_point, (245,117,66), 2)\n",
    "\n",
    "    # Draw the keypoints\n",
    "    for idx in keypoints_to_draw:\n",
    "        point = landmark_points[idx]\n",
    "        cv2.circle(image, point, 2, (245,66,230), thickness=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute angle\n",
    "def calculate_angle(v1, v2, joint):\n",
    "    \n",
    "    dot_product = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "    angle_radians = np.arccos(np.clip(dot_product, -1.0, 1.0))  # Clip for stability\n",
    "    angle_degrees = np.degrees(angle_radians)\n",
    "\n",
    "    cross_product = v1[0] * v2[1] - v1[1] * v2[0]\n",
    "    \n",
    "    if cross_product > 0:\n",
    "       angle_direction = -1\n",
    "    else:\n",
    "        angle_direction = 1\n",
    "    \n",
    "    if joint == 'hip':\n",
    "        angle_direction = -1 if v2[0]<0 else 1\n",
    "    else:\n",
    "        # angle_direction = 1 if cross_product > 0 else -1 \n",
    "        angle_direction = 1\n",
    "    \n",
    "    angle = angle_direction*angle_degrees\n",
    "\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('video_sample.avi')\n",
    "\n",
    "hip_angle_over_time = []\n",
    "knee_angle_over_time = []\n",
    "# Define the codec and create VideoWriter object\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output_video.avi', fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "\n",
    "# Setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5, static_image_mode=False, model_complexity=2) as pose:\n",
    "    while cap.isOpened():\n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame_height, frame_width, _ = frame.shape\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "    \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "         # Extract landmarks\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "        # Call the function to draw keypoints and connections\n",
    "        draw_keypoints_and_connections(image, landmarks, 'right')  # Use 'right' or 'left' as needed\n",
    "\n",
    "        #### ADICIONE CÓDIGO PARA EXTRAIR OS KEYPOINTS RELAVANTES, CALCULAR OS VETORES RELAVANTES PARA A CALCULAR O ÂNGULO DO QUADRIL E DO JOELHO PARA A MARCHA. #####\n",
    "        #### PARA CADA FRAME FAÇA UM APPEND DOS VALORES DOS ÂNGULOS NAS LISTAS HIP_ANGLE_OVER_TIME E kNEE_ANGLE_OVER_TIME #####\n",
    "\n",
    "        \n",
    "        # write frame into the file 'output_video.avi'\n",
    "        out.write(image)\n",
    "        # Show the image\n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots hip angle over time\n",
    "plt.figure()\n",
    "plt.plot(hip_angle_over_time)\n",
    "plt.title('Hip Angle Over Time')\n",
    "plt.xlabel('Frame')\n",
    "plt.ylabel('Angle (degrees)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots knee angle over time\n",
    "plt.figure()\n",
    "plt.plot(knee_angle_over_time)\n",
    "plt.title('Knee Angle Over Time')\n",
    "plt.xlabel('Frame')\n",
    "plt.ylabel('Angle (degrees)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
