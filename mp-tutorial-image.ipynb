{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np \n",
    "\n",
    "# Import MediaPipe Drawing module\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "# Import MediaPipe Pose module\n",
    "mp_pose = mp.solutions.pose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to draw keypoints and connections\n",
    "def draw_keypoints_and_connections(image, landmarks, mode):\n",
    "    # Get image dimensions\n",
    "    height, width, _ = image.shape\n",
    "    # Initialize list to the landmarks pixel coordinates\n",
    "    landmark_points = []\n",
    "    for landmark in landmarks:\n",
    "        landmark_point = (int(landmark.x * width), int(landmark.y * height))\n",
    "        landmark_points.append(landmark_point)\n",
    "\n",
    "    # Define connections for 'all' mode, excluding face and hand landmarks\n",
    "    connections_all = []\n",
    "    for conn in mp_pose.POSE_CONNECTIONS:\n",
    "        exclude = False\n",
    "        for lm in conn:\n",
    "            if lm in range(0, 11) or lm in range(17, 23):\n",
    "                exclude = True\n",
    "                break\n",
    "        if not exclude:\n",
    "            connections_all.append(conn)\n",
    "\n",
    "  \n",
    "    # Define connections for 'right' mode\n",
    "    connections_right = [\n",
    "        (mp_pose.PoseLandmark.RIGHT_SHOULDER, mp_pose.PoseLandmark.RIGHT_HIP),\n",
    "        (mp_pose.PoseLandmark.RIGHT_HIP, mp_pose.PoseLandmark.RIGHT_KNEE),\n",
    "        (mp_pose.PoseLandmark.RIGHT_KNEE, mp_pose.PoseLandmark.RIGHT_HEEL),\n",
    "        (mp_pose.PoseLandmark.RIGHT_HEEL, mp_pose.PoseLandmark.RIGHT_FOOT_INDEX)\n",
    "    ]\n",
    "    # Define connections for 'left' mode\n",
    "    connections_left = [\n",
    "        (mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.LEFT_HIP),\n",
    "        (mp_pose.PoseLandmark.LEFT_HIP, mp_pose.PoseLandmark.LEFT_KNEE),\n",
    "        (mp_pose.PoseLandmark.LEFT_KNEE, mp_pose.PoseLandmark.LEFT_HEEL),\n",
    "        (mp_pose.PoseLandmark.LEFT_HEEL, mp_pose.PoseLandmark.LEFT_FOOT_INDEX)\n",
    "    ]\n",
    "\n",
    "    # Determine which keypoints and connections to draw\n",
    "    keypoints_to_draw = set()\n",
    "    connections_to_draw = []\n",
    "\n",
    "    # Add keypoints and connections to draw based on the mode\n",
    "    if mode == 'all':\n",
    "        for idx in range(11, 17):\n",
    "            keypoints_to_draw.add(idx)\n",
    "        for idx in range(23, 33):\n",
    "            keypoints_to_draw.add(idx)\n",
    "        connections_to_draw = connections_all\n",
    "\n",
    "    elif mode == 'right':\n",
    "        for connection in connections_right:\n",
    "            keypoints_to_draw.add(connection[0])\n",
    "            keypoints_to_draw.add(connection[1])\n",
    "        connections_to_draw = connections_right\n",
    "\n",
    "    elif mode == 'left':\n",
    "        for connection in connections_left:\n",
    "            keypoints_to_draw.add(connection[0])\n",
    "            keypoints_to_draw.add(connection[1])\n",
    "        connections_to_draw = connections_left\n",
    "\n",
    "    # Draw the connections\n",
    "    for connection in connections_to_draw:\n",
    "        start_point = landmark_points[connection[0]]\n",
    "        end_point = landmark_points[connection[1]]\n",
    "        cv2.line(image, start_point, end_point, (245,117,66), 2)\n",
    "\n",
    "    # Draw the keypoints\n",
    "    for idx in keypoints_to_draw:\n",
    "        point = landmark_points[idx]\n",
    "        cv2.circle(image, point, 2, (245,66,230), thickness=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute angle\n",
    "def calculate_angle(v1, v2, joint):\n",
    "    \n",
    "    dot_product = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "    angle_radians = np.arccos(np.clip(dot_product, -1.0, 1.0))  # Clip for stability\n",
    "    angle_degrees = np.degrees(angle_radians)\n",
    "\n",
    "    cross_product = v1[0] * v2[1] - v1[1] * v2[0]\n",
    "    \n",
    "    if cross_product > 0:\n",
    "       angle_direction = -1\n",
    "    else:\n",
    "        angle_direction = 1\n",
    "    \n",
    "    if joint == 'hip':\n",
    "        angle_direction = -1 if v2[0]<0 else 1\n",
    "    else:\n",
    "        angle_direction = 1 if cross_product > 0 else -1 \n",
    "    \n",
    "    angle = angle_direction*angle_degrees\n",
    "\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pose Estimation in an image\n",
    "\n",
    "# Define the path to image file \n",
    "image_path = 'curry.jpg'\n",
    "# Read image from specified path\n",
    "\n",
    "\n",
    "# Create pose object \n",
    "with mp_pose.Pose(min_detection_confidence=0.05, min_tracking_confidence=0.5, model_complexity=1, static_image_mode=True) as pose:\n",
    "    # Read image from specified path\n",
    "    frame = cv2.imread(image_path)\n",
    "    # Convert the image from BGR (OpenCV default) to RGB as required by MediaPipe.\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    # Prevent image from being written to improve performance\n",
    "    image.flags.writeable = False\n",
    "    \n",
    "    # Process the image to detect pose landmarks\n",
    "    results = pose.process(image)\n",
    "   \n",
    "    # Recolor back to BGR\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    # Render detections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                            mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                            mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                )               \n",
    "        \n",
    "\n",
    "    cv2.imshow('MediaPipe Detection', image)\n",
    "    cv2.waitKey(0)  \n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Keypoints from an image\n",
    "\n",
    "# Define the path to image file \n",
    "image_path = 'curry.jpg'\n",
    "# Read image from specified path\n",
    "frame = cv2.imread(image_path)\n",
    "frame_height, frame_width, _ = frame.shape\n",
    "\n",
    "# Create pose object \n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5, model_complexity=1, static_image_mode=True) as pose:\n",
    "    # Convert the image from BGR (OpenCV default) to RGB as required by MediaPipe.\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    # Prevent image from being written to improve performance\n",
    "    image.flags.writeable = False\n",
    "    \n",
    "    # Process the image to detect pose landmarks\n",
    "    results = pose.process(image)\n",
    "   \n",
    "    # Recolor back to BGR\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Extract landmarks\n",
    "    try:\n",
    "        landmarks = results.pose_landmarks.landmark\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Render detections\n",
    "    draw_keypoints_and_connections(image, landmarks, 'all')  # Use 'right' or 'left' as needed     \n",
    "\n",
    "\n",
    "    right_shoulder = np.rint(np.array([landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x * frame_width,\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y * frame_height]))\n",
    "    right_elbow = np.rint(np.array([landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x * frame_width,\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y * frame_height]))\n",
    "    right_wrist = np.rint(np.array([landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x * frame_width,\n",
    "                            landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y * frame_height]))   \n",
    "\n",
    "    \n",
    "\n",
    "    a = right_shoulder - right_elbow\n",
    "    b = right_wrist - right_elbow\n",
    "    \n",
    "\n",
    "    hip_angle = round(calculate_angle(a, b, 'elbow'))\n",
    "\n",
    "  \n",
    "    \n",
    "\n",
    "    # Display the angle at the hip position in yellow with a smaller font size\n",
    "    cv2.putText(image, str(hip_angle), \n",
    "                tuple(right_elbow.astype(int)), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1, cv2.LINE_AA)\n",
    "    \n",
    "    \n",
    "    # Show the image\n",
    "    cv2.imshow('Pose', image)\n",
    "    \n",
    "    cv2.waitKey(0)  \n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model to /home/lucasmedino/anaconda3/envs/mp-workshop-notebook/lib/python3.9/site-packages/mediapipe/modules/pose_landmark/pose_landmark_heavy.tflite\n"
     ]
    }
   ],
   "source": [
    "# Open video file stream for video capture\n",
    "cap = cv2.VideoCapture('video_sample.avi')\n",
    "## Setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5, static_image_mode=False, model_complexity=2) as pose:\n",
    "    # Loops through each frame in the video\n",
    "    while cap.isOpened():\n",
    "        # read frame\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "        landmarks = results.pose_landmarks.landmark\n",
    "    \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Render detections\n",
    "        draw_keypoints_and_connections(image, landmarks, 'right')  # Use 'right' or 'left' as needed           \n",
    "        \n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
